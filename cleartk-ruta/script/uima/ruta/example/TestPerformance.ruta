PACKAGE uima.ruta.example;

// import the types of this type system:
TYPESYSTEM org.cleartk.TypeSystem;

// define and import an external dictionary containing first names
WORDLIST kwds_time = 'lemmas/time.txt';
WORDLIST kwds_LTD = 'lemmas/LTD.txt';
WORDLIST kwds_constraint = 'lemmas/constraints.txt';
WORDLIST kwds_event = 'lemmas/events.txt';

DECLARE Annotation PerformanceSentence;

// define some useful annotations
DECLARE Annotation TokenTime(STRING pos, STRING lemma);
DECLARE Annotation TokenLTD(STRING pos, STRING lemma);
DECLARE Annotation TokenStart(STRING pos, STRING lemma);
DECLARE Annotation TokenEnd(STRING pos, STRING lemma);
DECLARE Annotation TokenConstraint(STRING pos, STRING lemma, Annotation sentence);
DECLARE Annotation TokenEvent(STRING pos, STRING lemma);

//disambiguation of any word of seconds(time) or any 
NUM Token{REGEXP(".*second[s]?", true)->Token.lemma="#time#"};

//Mark perfomance tokens that matches with the list of taxonomies words
Token{INLIST(kwds_constraint,Token.lemma) -> CREATE(TokenConstraint, "pos" = Token.pos, "lemma" = Token.lemma, "sentence" = 0)};
Token{INLIST(kwds_time,Token.lemma) -> CREATE(TokenTime, "pos" = Token.pos, "lemma" = Token.lemma)};
Token{INLIST(kwds_LTD,Token.lemma) -> CREATE(TokenLTD, "pos" = Token.pos, "lemma" = Token.lemma)};
Token{INLIST(kwds_event,Token.lemma) -> CREATE(TokenEvent, "pos" = Token.pos, "lemma" = Token.lemma)};

Token{REGEXP("start", true) -> CREATE(TokenStart, "pos" = Token.pos, "lemma" = Token.lemma)};
Token{REGEXP("end", true) -> CREATE(TokenEnd, "pos" = Token.pos, "lemma" = Token.lemma)};

Sentence{OR(
  AND (CONTAINS(TokenEvent), CONTAINS(TokenTime)),
  AND (CONTAINS(TokenEvent), CONTAINS(TokenConstraint)),
  AND (CONTAINS(TokenEvent), CONTAINS(TokenLTD)),
  AND (CONTAINS(TokenEvent), CONTAINS(TokenStart), CONTAINS(TokenEnd)),
  AND (CONTAINS(TokenTime), CONTAINS(TokenConstraint)),
  AND (CONTAINS(TokenLTD), CONTAINS(TokenConstraint))
) -> MARK(PerformanceSentence)};

TokenConstraint{-PARTOF(PerformanceSentence) -> UNMARK(TokenConstraint)};
TokenTime{-PARTOF(PerformanceSentence) -> UNMARK(TokenTime)};
TokenLTD{-PARTOF(PerformanceSentence) -> UNMARK(TokenLTD)};
TokenEvent{-PARTOF(PerformanceSentence) -> UNMARK(TokenEvent)};
TokenStart{-PARTOF(PerformanceSentence) -> UNMARK(TokenStart)};
TokenEnd{-PARTOF(PerformanceSentence) -> UNMARK(TokenEnd)};
Token{-PARTOF(PerformanceSentence) -> UNMARK(Token)};
