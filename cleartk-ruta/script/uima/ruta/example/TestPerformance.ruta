PACKAGE uima.ruta.example;

// import the types of this type system:
TYPESYSTEM org.cleartk.TypeSystem;

// define and import an external dictionary containing first names
WORDLIST kwds_time = 'lemmas/time.txt';
WORDLIST kwds_LTD = 'lemmas/LTD.txt';
WORDLIST kwds_constraint = 'lemmas/constraints.txt';
WORDLIST kwds_event = 'lemmas/events.txt';

// define some useful annotations
DECLARE Annotation tokenTime(STRING pos, STRING lemma);
DECLARE Annotation tokenLTD(STRING pos, STRING lemma);
DECLARE Annotation tokenStart(STRING pos, STRING lemma);
DECLARE Annotation tokenEnd(STRING pos, STRING lemma);
DECLARE Annotation tokenConstraint(STRING pos, STRING lemma);
DECLARE Annotation tokenEvent(STRING pos, STRING lemma);

DECLARE performanceSentence;

//disambiguation of any word of seconds(time) or any 
NUM Token{REGEXP(".*second[s]?", true)->Token.lemma="#time#"};

//Mark perfomance tokens that matches with the list of taxonomies words
Token{INLIST(kwds_constraint,Token.lemma) -> CREATE(tokenConstraint, "pos" = Token.pos, "lemma" = Token.lemma)};
Token{INLIST(kwds_time,Token.lemma) -> CREATE(tokenTime, "pos" = Token.pos, "lemma" = Token.lemma)};
Token{INLIST(kwds_LTD,Token.lemma) -> CREATE(tokenLTD, "pos" = Token.pos, "lemma" = Token.lemma)};
Token{INLIST(kwds_event,Token.lemma) -> CREATE(tokenEvent, "pos" = Token.pos, "lemma" = Token.lemma)};

Token{REGEXP("start", true) -> CREATE(tokenStart, "pos" = Token.pos, "lemma" = Token.lemma)};
Token{REGEXP("end", true) -> CREATE(tokenEnd, "pos" = Token.pos, "lemma" = Token.lemma)};

Sentence{OR(
  AND (CONTAINS(tokenEvent), CONTAINS(tokenTime)),
  AND (CONTAINS(tokenEvent), CONTAINS(tokenConstraint)),
  AND (CONTAINS(tokenEvent), CONTAINS(tokenLTD)),
  AND (CONTAINS(tokenEvent), CONTAINS(tokenStart), CONTAINS(tokenEnd)),
  AND (CONTAINS(tokenTime), CONTAINS(tokenConstraint)),
  AND (CONTAINS(tokenLTD), CONTAINS(tokenConstraint))
) -> MARK(performanceSentence)};
